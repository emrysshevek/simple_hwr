{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "from hwr_utils import *\n",
    "from hwr_utils.stroke_plotting import *\n",
    "from hwr_utils.stroke_recovery import *\n",
    "import json\n",
    "from gen_preds_offline import load_all_gts\n",
    "\n",
    "from hwr_utils import visualize\n",
    "from torch.utils.data import DataLoader\n",
    "from loss_module.stroke_recovery_loss import StrokeLoss\n",
    "from trainers import TrainerStrokeRecovery\n",
    "from hwr_utils.stroke_dataset import BasicDataset\n",
    "from hwr_utils.stroke_recovery import *\n",
    "from hwr_utils import utils\n",
    "from torch.optim import lr_scheduler\n",
    "from models.stroke_model import StrokeRecoveryModel\n",
    "from train_stroke_recovery import parse_args, graph\n",
    "from hwr_utils.hwr_logger import logger\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(pred,gt):\n",
    "    #return pred\n",
    "    return move_bad_points(reference=pred, moving_component=gt, reference_is_image=True)\n",
    "\n",
    "def eval_only(dataloader, model):\n",
    "    final_out = []\n",
    "    for i, item in enumerate(dataloader):\n",
    "        preds = TrainerStrokeRecovery.eval(item[\"line_imgs\"], model,\n",
    "                                           label_lengths=item[\"label_lengths\"],\n",
    "                                           relative_indices=config.pred_relativefy,\n",
    "                                           sigmoid_activations=config.sigmoid_indices)\n",
    "\n",
    "        # Pred comes out of eval WIDTH x VOCAB\n",
    "        preds_to_graph = [post_process(p, item[\"line_imgs\"][i]).permute([1, 0]) for i,p in enumerate(preds)]\n",
    "        globals().update(locals())\n",
    "        # Get GTs, save to file\n",
    "        if i<10:\n",
    "            # Save a sample\n",
    "            save_folder = graph(item, preds=preds_to_graph, _type=\"eval\", epoch=\"current\", config=config, save_folder=None)\n",
    "            output_path = (save_folder / \"data\")\n",
    "            output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        names = [Path(p).stem.lower() for p in item[\"paths\"]]\n",
    "        output = []\n",
    "        for ii, name in enumerate(names):\n",
    "            if name in GT_DATA:\n",
    "                output.append({\"stroke\": preds[ii].detach().numpy(), \"text\":GT_DATA[name]})\n",
    "            else:\n",
    "                print(f\"{name} not found\")\n",
    "        utils.pickle_it(output, output_path / f\"{i}.pickle\")\n",
    "        np.save(output_path / f\"{i}.npy\", output)\n",
    "        final_out += output\n",
    "    utils.pickle_it(final_out, output_path / f\"all_data.pickle\")\n",
    "    np.save(output_path / f\"all_data.npy\", final_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/data/GitHub/simple_hwr/RESULTS/pretrained/brodie_123/stroke_number_with_BCE_RESUME2.yaml\n",
      "Experiment: new_experiment01, Results Directory: /home/taylor/github/simple_hwr/RESULTS/ver4/20200229_223630-stroke_number_with_BCE_RESUME/new_experiment01\n",
      "Effective logging level: 20\n",
      "Using config file /media/data/GitHub/simple_hwr/RESULTS/pretrained/brodie_123/stroke_number_with_BCE_RESUME2.yaml\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | nan% | 48% |\n",
      "Creating LSTM: in:1024 hidden:128 dropout:0.5 layers:2 out:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../hwr_utils/utils.py:33: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return fix_scientific_notation(yaml.load(config.open(mode=\"r\")))\n",
      "../../hwr_utils/utils.py:548: UserWarning: cross_entropy loss already added to stats\n",
      "  warnings.warn(f\"{loss['name']} loss already added to stats\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:35:59 INFO COORD CONV: y_rel\n",
      "16:35:59 INFO COORD CONV: y_rel\n",
      "16:35:59 INFO Zero center False\n",
      "16:35:59 INFO Zero center False\n",
      "16:35:59 INFO RECT X Coord: False\n",
      "16:35:59 INFO RECT X Coord: False\n",
      "16:35:59 INFO Normalized X Coord: True\n",
      "16:35:59 INFO Normalized X Coord: True\n",
      "16:35:59 INFO Using ABS+REL X Coord Channels: False\n",
      "16:35:59 INFO Using ABS+REL X Coord Channels: False\n",
      "16:35:59 INFO X: False\n",
      "16:35:59 INFO X: False\n",
      "16:36:00 INFO Y: False\n",
      "16:36:00 INFO Y: False\n",
      "16:36:00 INFO ('Current dataset: ', PosixPath('/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/lines'))\n",
      "16:36:00 INFO ('Current dataset: ', PosixPath('/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/lines'))\n",
      "{'Actual_Loss_Function_train': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'Actual_Loss_Function_train', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'training_pred_count', 'x_plot': 'epoch_decimal', 'train': True}, 'nn_train': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'nn_train', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'training_pred_count', 'x_plot': 'epoch_decimal', 'train': True}, 'point_count_train': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Points Predicted', 'ymax': None, 'name': 'point_count_train', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'training_pred_count', 'x_plot': 'epoch_decimal', 'train': True}, 'l1_with_stroke_numbers_train': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'l1_with_stroke_numbers_train', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'training_pred_count', 'x_plot': 'epoch_decimal', 'train': True}, 'dtw_train': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'dtw_train', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'training_pred_count', 'x_plot': 'epoch_decimal', 'train': True}, 'cross_entropy_train': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'cross_entropy_train', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'training_pred_count', 'x_plot': 'epoch_decimal', 'train': True}, 'Actual_Loss_Function_test': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'Actual_Loss_Function_test', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'test_pred_length_static', 'x_plot': 'epoch_decimal', 'train': False}, 'nn_test': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'nn_test', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'test_pred_length_static', 'x_plot': 'epoch_decimal', 'train': False}, 'point_count_test': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Points Predicted', 'ymax': None, 'name': 'point_count_test', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'test_pred_length_static', 'x_plot': 'epoch_decimal', 'train': False}, 'l1_with_stroke_numbers_test': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'l1_with_stroke_numbers_test', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'test_pred_length_static', 'x_plot': 'epoch_decimal', 'train': False}, 'dtw_test': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'dtw_test', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'test_pred_length_static', 'x_plot': 'epoch_decimal', 'train': False}, 'cross_entropy_test': {'y': [None], 'x': [0], 'current_weight': 0, 'current_sum': 0, 'accumlator_active': False, 'updated_since_plot': False, 'accumulator_freq': None, 'x_title': 'Epochs', 'y_title': 'Loss', 'ymax': None, 'name': 'cross_entropy_test', 'plot': True, 'plot_update_length': 1, 'last_weight_step': 0, 'x_counter': <hwr_utils.stattrack.Counter object at 0x7fd9f5ce1d60>, 'x_weight': 'test_pred_length_static', 'x_plot': 'epoch_decimal', 'train': False}}\n",
      "16:36:00 INFO ('Relative Idices', [0])\n",
      "16:36:00 INFO ('Relative Idices', [0])\n",
      "/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/gts/lines/txt/test.json\n",
      "/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/gts/lines/txt/training.json\n",
      "/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/gts/lines/txt/val1.json\n",
      "/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/gts/lines/txt/val2.json\n",
      "Dataloader size 9862\n",
      "Number of images: 13353\n",
      "Number of GTs: 9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../hwr_utils/utils.py:788: UserWarning: Could not load from all_stats.json\n",
      "  warnings.warn(\"Could not load from all_stats.json\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StrokeRecoveryModel(\n",
       "  (rnn): BidirectionalRNN(\n",
       "    (rnn): LSTM(1024, 128, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "    (embedding): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       "  (cnn): CNN(\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=(4, 1), padding=1, dilation=1, ceil_mode=False)\n",
       "    (cnn): Sequential(\n",
       "      (conv0): CoordConv(\n",
       "        (addcoords): AddCoords()\n",
       "        (conv): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (pooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "      (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu4): ReLU(inplace=True)\n",
       "      (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu5): ReLU(inplace=True)\n",
       "      (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "      (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu6): ReLU(inplace=True)\n",
       "      (upsample): Interpolate()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global epoch, device, trainer, batch_size, output, loss_obj, x_relative_positions, config, LOGGER\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "PROJ_ROOT = \"/media/data/GitHub/simple_hwr/\"\n",
    "config_path = \"/media/data/GitHub/simple_hwr/RESULTS/pretrained/brodie_123/stroke_number_with_BCE_RESUME2.yaml\"\n",
    "load_path_override = \"/media/data/GitHub/simple_hwr/RESULTS/pretrained/brodie_123/stroke_number_with_BCE_RESUME2_model_123_epochs.pt\"\n",
    "\n",
    "_load_path_override = Path(load_path_override)\n",
    "\n",
    "OUTPUT = PROJ_ROOT / Path(\"RESULTS/OFFLINE_PREDS/\") / _load_path_override.stem\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Make these the same as whereever the file is being loaded from; make the log_dir and results dir be a subset\n",
    "# main_model_path, log_dir, full_specs, results_dir, load_path\n",
    "\n",
    "\n",
    "config = utils.load_config(config_path, hwr=False, results_dir_override=OUTPUT.as_posix())\n",
    "\n",
    "# Free GPU memory if necessary\n",
    "if config.device == \"cuda\":\n",
    "    utils.kill_gpu_hogs()\n",
    "\n",
    "batch_size = config.batch_size\n",
    "\n",
    "vocab_size = config.vocab_size\n",
    "\n",
    "device=torch.device(config.device)\n",
    "#device=torch.device(\"cpu\")\n",
    "\n",
    "#output = utils.increment_path(name=\"Run\", base_path=Path(\"./results/stroke_recovery\"))\n",
    "output = Path(config.results_dir)\n",
    "output.mkdir(parents=True, exist_ok=True)\n",
    "folder = Path(config.dataset_folder)\n",
    "\n",
    "# OVERLOAD\n",
    "folder = PROJ_ROOT / Path(\"data/prepare_IAM_Lines/lines/\")\n",
    "gt_path = PROJ_ROOT / Path(\"data/prepare_IAM_Lines/gts/lines/txt\")\n",
    "#folder = Path(r\"fish:////taylor@localhost:2222/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/\")\n",
    "#folder = Path(\"/media/data/GitHub/simple_hwr/data/prepare_IAM_Lines/words\")\n",
    "model = StrokeRecoveryModel(vocab_size=vocab_size, device=device, cnn_type=config.cnn_type, first_conv_op=config.coordconv, first_conv_opts=config.coordconv_opts).to(device)\n",
    "\n",
    "## Loader\n",
    "logger.info((\"Current dataset: \", folder))\n",
    "# Dataset - just expecting a folder\n",
    "eval_dataset=BasicDataset(root=folder, cnn=model.cnn)\n",
    "\n",
    "eval_loader=DataLoader(eval_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=6,\n",
    "                              collate_fn=eval_dataset.collate, # this should be set to collate_stroke_eval\n",
    "                              pin_memory=False)\n",
    "config.n_train_instances = None\n",
    "config.n_test_instances = len(eval_loader.dataset)\n",
    "config.n_test_points = None\n",
    "\n",
    "## Stats\n",
    "config.use_visdom = False\n",
    "if config.use_visdom:\n",
    "    visualize.initialize_visdom(config[\"full_specs\"], config)\n",
    "utils.stat_prep_strokes(config)\n",
    "\n",
    "# Create loss object\n",
    "config.loss_obj = StrokeLoss(loss_names=config.loss_fns, loss_stats=config.stats, counter=config.counter)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.0005 * batch_size/32)\n",
    "config.scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=.95)\n",
    "trainer = TrainerStrokeRecovery(model, optimizer, config=config, loss_criterion=config.loss_obj)\n",
    "\n",
    "config.model = model\n",
    "config.load_path = load_path_override if (\"load_path_override\" in locals()) else config.load_path\n",
    "\n",
    "config.sigmoid_indices = TrainerStrokeRecovery.get_indices(config.pred_opts, \"sigmoid\")\n",
    "\n",
    "# Load the GTs\n",
    "GT_DATA = load_all_gts(gt_path)\n",
    "print(\"Number of images: {}\".format(len(eval_loader.dataset)))\n",
    "print(\"Number of GTs: {}\".format(len(GT_DATA)))\n",
    "\n",
    "## LOAD THE WEIGHTS\n",
    "utils.load_model_strokes(config) # should be load_model_strokes??????\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x must consist of vectors of length 2 but has shape (1, 2, 1628)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a7776fc5fe45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-00ea8e9b45ca>\u001b[0m in \u001b[0;36meval_only\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Pred comes out of eval WIDTH x VOCAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpreds_to_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"line_imgs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Get GTs, save to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-00ea8e9b45ca>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Pred comes out of eval WIDTH x VOCAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpreds_to_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"line_imgs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Get GTs, save to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-00ea8e9b45ca>\u001b[0m in \u001b[0;36mpost_process\u001b[0;34m(pred, gt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#return pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmove_bad_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_component\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_is_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/GitHub/simple_hwr/hwr_utils/stroke_recovery.py\u001b[0m in \u001b[0;36mmove_bad_points\u001b[0;34m(reference, moving_component, reference_is_image, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmove_bad_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_component\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_is_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m     \u001b[0mnearest_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nearest_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_component\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_is_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m     \u001b[0mmoving_component\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnearest_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmoving_component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/GitHub/simple_hwr/hwr_utils/stroke_recovery.py\u001b[0m in \u001b[0;36mget_nearest_point\u001b[0;34m(reference, moving_component, reference_is_image, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mkd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving_component\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# How far do we have to move the GT's to match the predictions?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0mnearest_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbor_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnearest_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hwr5/lib/python3.8/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, x, k, eps, p, distance_upper_bound)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x must consist of vectors of length %d but has shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only p-norms with 1<=p<=infinity permitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x must consist of vectors of length 2 but has shape (1, 2, 1628)"
     ]
    }
   ],
   "source": [
    "eval_only(eval_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [post_process(p, item[\"line_imgs\"][i]).permute([1, 0]) for i,p in enumerate(preds)]\n",
    "print(preds[0])\n",
    "#print(preds_to_graph[0])\n",
    "# print(preds_to_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = item[\"line_imgs\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(np.squeeze(i), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwr5",
   "language": "python",
   "name": "hwr5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
